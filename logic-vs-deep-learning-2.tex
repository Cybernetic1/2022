\input{../YKY-preamble.tex}
\setmainfont[BoldFont=Alibaba_Sans_Regular.otf,ItalicFont=Alibaba_Sans_Light_Italic.otf]{Alibaba_Sans_Light.otf}
	
\usepackage[active,tightpage]{preview}		% for continuous page(s)
\renewcommand{\PreviewBorder}{0.5cm}
\renewcommand{\thempfootnote}{\arabic{mpfootnote}}

\usepackage[absolute,overlay]{textpos}		% for page number on upper left corner

\usepackage{color}
\usepackage{mathtools}
\usepackage[hyperfootnotes=false]{hyperref}

% \usepackage[backend=biber,style=numeric]{biblatex}
% \bibliography{../AGI-book}
% \renewcommand*{\bibfont}{\footnotesize}

\usetikzlibrary{shapes}
\usepackage[export]{adjustbox}				% ??
\usepackage{verbatim} % for comments
% \usepackage{newtxtext,newtxmath}	% Times New Roman font

% \numberwithin{equation}{subsection}

\newcommand{\underdash}[1]{%
	\tikz[baseline=(toUnderline.base)]{
		\node[inner sep=1pt,outer sep=10pt] (toUnderline) {#1};
		\draw[dashed] ([yshift=-0pt]toUnderline.south west) -- ([yshift=-0pt]toUnderline.south east);
	}%
}%


%\DeclareSymbolFont{symbolsC}{U}{txsyc}{m}{n}
%\DeclareMathSymbol{\strictif}{\mathrel}{symbolsC}{74}
\DeclareSymbolFont{AMSb}{U}{msb}{m}{n}
\DeclareSymbolFontAlphabet{\mathbb}{AMSb}
% \setmathfont{Latin Modern Math}
\DeclareMathOperator*{\argmin}{arg\,min}

% \usepackage[most]{tcolorbox}
\tcbset{on line, 
	boxsep=4pt, left=0pt,right=0pt,top=0pt,bottom=0pt,
	colframe=red,colback=pink,
	highlight math style={enhanced}
}
\newcommand{\atom}{\vcenter{\hbox{\tcbox{....}}}}

% \newcommand{\emp}[1]{{\color{violet}\textbf{#1}}}
\let\oldtextbf\textbf
\renewcommand{\textbf}[1]{\textcolor{blue}{\oldtextbf{#1}}}

\newcommand{\logic}[1]{{\color{violet}{\textit{#1}}}}
\newcommand*\smileFace{$\vcenter{\hbox{\includegraphics[scale=0.6]{../smiley.jpg}}}$}
\newcommand{\underconst}{\includegraphics[scale=0.5]{../2020/UnderConst.png}}
\newcommand{\KBsymbol}{\vcenter{\hbox{\includegraphics[scale=1]{../KB-symbol.png}}}}
\newcommand{\witness}{\scalebox{0.6}{$\blacksquare$}}
% \newcommand{\Heytingarrow}{\mathrel{-}\mathrel{\triangleright}}
% \providecommand\Heytingarrow{\relbar\joinrel\mathrel{\vcenter{\hbox{\scalebox{0.75}{$\rhd$}}}}}

\begin{document}

\begin{preview}

\cc{
\title{\vspace{-1.5cm} \bfseries\color{blue}{\Large 逻辑与深度学习的关系}}
}{
\title{\vspace{-1.5cm} \bfseries\color{blue}{\Large Comparison of Logic AI and Deep Learning}}
}

% \author{YKY} % Your name
\date{\vspace{-2cm}} % Date, can be changed to a custom date

\maketitle

\setcounter{section}{-1}

% (1) Circled page number on upper left corner
\begin{textblock*}{5cm}(2.1cm,2.3cm) % {block width} (coords) 
{\color{red}{\large \textcircled{\small 1}}}
\end{textblock*}

\begin{minipage}{\textwidth}
\setlength{\parskip}{0.4\baselineskip}

\cc{这是经典逻辑 AI 的最基本运作模式：
}{
This is the most basic operation of classical logic-based AI:
}
\begin{equation}
\cc{  \vcenter{\hbox{\includegraphics[scale=1]{LBAI-basic-config.png}}}     }{
      \vcenter{\hbox{\includegraphics[scale=1]{LBAI-basic-config-en.png}}}  }
\end{equation}

\cc{它其实包含了两个算法：
}{
It contains two algorithms:
}
\begin{itemize}
\item \textbf{matching} (unification): \\
\cc{逻辑 rules 是包含变量的条件命题， \\
}{
Logic rules are conditional propositions involving variables, \\
}
\cc{例如 \tab \logic{$\forall x. \mbox{是人}(x) \Rightarrow \mbox{会死}(x). $ }\\
}{
eg: \tab \logic{$\forall x. \; \mbox{human}(x) \Rightarrow \mbox{mortal}(x). $ }\\
}
\cc{Unification 判定一条 rule 是否可以 apply 到某逻辑命题上，\\
}{
Unification determines whether a rule can be applied to a proposition,
}
\cc{例如：\logic{是人(苏格拉底)} 可以跟上式的左边 unify. \\
}{
eg: \logic{human(Socrates)} can unify with the left side of the above rule. \\
}
\cc{Matching 的结果是得到一推 instantiated（特例化，即不包含变量）的命题。
}{
The goal of Matching is to get an instantiated proposition (ie, specialized, does not contain variables).
}

\item \textbf{forward- or backward-chaining} (resolution): \\
\cc{由已知事实 推导出新结论，或反过来，判断某给定的新结论是否成立。 \\
}{
Deduce new conclusions from known facts, or conversely, judge whether a given conclusion can be proven. \\
}
\cc{例如：\logic{ 是人(苏格拉底) $\Rightarrow$ 会死(苏格拉底) $\;\; \wedge$ 是人(苏格拉底) } \\
}{
eg: \logic{human (Socrates) $\wedge \;$ human(Socrates) $\Rightarrow$ mortal(Socrates)} \\
}
\cc{可以推出：\logic{会死(苏格拉底)}。
}{
From which can be deduced: \logic{mortal (Socrates)}.
}
\end{itemize}

\cc{深度学习的特点，就是将
}{
The special thing about deep learning is that it can imitate this inference process:
}
\begin{equation}
\mbox{\cc{状态}{state}}_t  \vdash \mbox{\cc{状态}{state}}_{t+1}
\end{equation}
\cc{的逻辑推导过程，通通纳入进去一个非常复杂的非线性函数（= 深度神经网络）里面。 这样做以后，上述的逻辑结构被 ``mingled'' 在一起，以至于很难分辨了。 但也正是由于这种「大杂烩」，深度神经网络 将一套复杂的组合算法 压缩成数量不算太多的一层层的参数。 它同时可以做 learning 和 inference 这两个动作。 这种简单粗暴的方法，其实非常有效率，要超越它的速度并不容易！
}{
with a highly complicated non-linear function (ie, a deep neural network).  By doing so, the logic rules are ``mingled'' together so that it's hard to tell them apart.  But it is precisely because of this ``mingling'' that a deep neural network compresses a huge number of combinatorial logic rules into a smaller number of parameters (network weights).  It can perform both learning and inference.  This simple and crude method is actually extremely efficient, and it is not easy to surpass its speed!
}

\cc{我们知道（或推测）一个智能系统 应该具有 符号逻辑的结构。 这点知识可不可以用来 约束/加速 深度神经网络？ 答案似乎是有可能的。 现时 state-of-the-art 处理 视觉的 CNN 和 处理文字的 GPT，它们都有内部结构， \textbf{而不是 fully-connected}，而且 这内部结构 对应于 被处理的资料的结构。 因此我们有理由相信，逻辑结构 可以用来约束 深度神经网络的结构，达到加速。 
}{
We know (or speculate) that an intelligent system should possess the structure of symbolic logic.  Can this insight be used to constrain or accelerate deep neural networks?  The answer seems to be yes.  The current state-of-the-art CNN (for vision) and GPT (for language) both have specialized internal structure, instead of just being \textbf{fully-connected}, and that internal structure is suited to the structure of the data being processed.  We have reason to believe that logical structure can be used to constrain deep neural networks to accelerate logical learning.
}

\end{minipage}
\end{preview}

\begin{preview}
\begin{minipage}{\textwidth}
\setlength{\parskip}{0.4\baselineskip}

\begin{textblock*}{20cm}(2.1cm,2cm) % {block width} (coords) 
	{\color{red}{\large \textcircled{\small 2}}}
	\hspace{8cm}
	\color{blue}{\footnotesize \cc{逻辑与深度学习}{Logic and Deep Learning}}
\end{textblock*}
\vspace*{0.3cm} 

\cc{接下来我们详细一点看逻辑系统的结构：
}{
Next, let's look at the logic-based AI architecture in detail.
}

\cc{Knowledge Base 里面有很多 rules，系统要将这些 rules 逐一 match with 系统状态 (= working memory) 里面的命题：
}{
There are a huge number of rules in the Knowledge Base, and the system needs to match these rules one by one against propositions in the system's state (= working memory):
}
\begin{equation}
\vcenter{\hbox{\includegraphics[scale=1]{rete-explained-1b.png}}}
\end{equation}
\cc{成功 matched 的 rules 可以导出新的结论，加进 working memory 的状态 里面。
}{
Successfully matched rules generate new conclusions that can be added back to the state / working memory.
}

\cc{这个复杂的操作，完全被一个神经网络取代。 或者可以更抽象地说：
}{
This complicated process is entirely replaced by a neural network.  Or more abstractly:
}
\begin{equation}
\label{eqn:some-kind-of-memory}
\cc{ \vcenter{\hbox{\includegraphics[scale=1]{some-kind-of-memory.png}}}    }{
     \vcenter{\hbox{\includegraphics[scale=1]{some-kind-of-memory-en.png}}} }
\end{equation}

\cc{而以 Transformer 来说，它是一种 输入元 \textbf{之间} 的记忆体（这记忆就储存在 $Q, K, V$ 矩阵里），而它 \textbf{implicitly} 做到了 rules 的作用：
}{
For the Transformer, this is a kind of memory stored \textbf{between} input elements (stored as the $Q, K, V$ matrices), and it \textbf{implicitly} plays the role of logic rules:
}
\begin{equation}
\label{fig:self-attention-as-Rete}
\vcenter{\hbox{\includegraphics[scale=0.9]{rete-explained-3b.png}}}
\end{equation}
\cc{换句话说，Transformer 内部有某种（扭曲了的）逻辑 rules 的结构。 那么很自然的问题就是：能否发掘更多 逻辑／逻辑系统 的结构？ 也就是说，公式 (\ref{eqn:some-kind-of-memory}) 可以有怎样的代数结构约束？ 这个问题 可以参考 范畴逻辑 的理论，还有 经典 logic-based AI 系统的理论。
}{
In other words, there are some sort of ``distorted'' logic rules inside the Transformer.  Naturally, we want to find out more structures of logic / logic-based systems.  That is, what kind of algebraic structure constrains (\ref{eqn:some-kind-of-memory})?  To answer this, we can take insights from categorical logic and classical logic-based AI.
}

\end{minipage}
\end{preview}

\begin{preview}
\begin{minipage}{\textwidth}
	
\setlength{\parskip}{0.4\baselineskip}
\begin{textblock*}{20cm}(2.1cm,2cm) % {block width} (coords) 
	{\color{red}{\large \textcircled{\small 3}}}
	\hspace{8cm}
	\color{blue}{\footnotesize \cc{逻辑与深度学习}{Logic and Deep Learning}}
\end{textblock*}
\vspace*{0.3cm} 

\cc{我们希望 勾画出公式 (\ref{eqn:some-kind-of-memory}) 需要具备的代数约束，但暂时先用文字描述比较容易：
}{
We wish to formulate, in algebraic terms, the constraints for (\ref{eqn:some-kind-of-memory}), but for now it is easier to describe in words:
}
\begin{itemize}
\cc{\item 状态是 \textbf{颗粒化} 的，它是某集合的元素，元素之间可交换，也就是 Transformer 的 equivariance. （注意： Transformer 有 equivariance，但 equivariance 未必一定要用 Transformer 实现）
}{
	\item The AI state is \textbf{granular}, as a set of elements, whose order can be permuted, corresponding to equivariance of the Transformer.  (Note: Transformers are equivariant, but equivariance does not necessarily require Transformers)
}

\cc{\item \textbf{深度结构}：例如多层网络，每层是函数的复合 (composition). Transformer 也用了深度结构。
}{
	\item \textbf{Deep structure}:  in the sense of having many layers, as composition of functions. The Transformer also has deep structure, with many layers of Self-Attention stacked up.
}

\cc{\item 逻辑 包括了 \textbf{命题}层次 和 \textbf{命题内部}层次 的 颗粒化。 后者是\textbf{谓词} (predicate) 逻辑的结构，例如： \logic{loves( John, Mary )}，也可以简单地将它视为 \textbf{代数元}之间的\textbf{乘积}，例如： \logic{John \bullet\  loves \bullet\   Mary}, 后者也叫做 ``word''.  （不同类别的代数元之间不一定容许乘积，因此有 groupoid 的概念，但暂时来说这细节不重要。） 现时重点是如何将 这两层的 颗粒化 结构 施加到深度神经网络上。 
}{
	\item Logic has granularity at the \textbf{proposition} level and at the \textbf{sub-propositional} level.  The latter is the structure of \textbf{predicate} logic, eg: \logic{loves( John, Mary )} can be represented as a \textbf{product} in an \textbf{algebra}: \logic{John \bullet\ loves \bullet\ Mary}, also called a ``word''.  The details are unimportant.  Our focus is on how to impose this 2-level granular structure onto deep neural networks.
}

\cc{\item 逻辑推导 每步只产生\textbf{一个}新的结论（或其概率分布），然后这个新的结论，再加入到旧的状态中，作为一个命题集合的元素，而旧状态也要 \textbf{遗忘} 一些命题，否则需要无限记忆。 这跟 Transformer 每次输出\textbf{一列}的 tokens 有点不同（虽然我们不太肯定 Transformer tokens 究竟对应于 命题 还是 谓词／原子概念）。 
}{
	\item Each step of logic inference produces \textbf{one} new conclusion (or a probability distribution over conclusions), and this new conclusion is added to the old state as an element in a set of propositions, and the old state also needs to \textbf{forget} some old propositions, otherwise infinite memory is required.  This is slightly different from the Transformer which always outputs the \textbf{same number} of tokens as its input. (We are unsure whether Transformer tokens correspond to propositions or to predicates / atomic concepts \footnote{This is answered in the next version}).
}

\cc{\item 逻辑 rule 通常只跟某几个前提有关，其它前提是\textbf{无关}的，例如： \logic{眼睛好看 $\wedge$ 鼻子好看 $\wedge$ 嘴巴好看 $\Rightarrow$ 帅}，跟 \logic{有钱} 或 \logic{穷} 无关。 Transformer 的 \textbf{softmax} 结构似乎也可以排除一些无关的 tokens 的影响。
}{
	\item A logic rule usually depends on some premises where other premises are \textbf{irrelevant};  For example: \logic{talk $\wedge$ dark $\wedge$ handsome $\Rightarrow$ attractive to women}, where \logic{rich} or \logic{poor} are irrelevant.  The Transformer's \textbf{softmax} seems to be a mechanism to exclude irrelevant tokens.
}

\cc{\item （可能还有其他的结构特征.....）
}{
	\item (There may be other structures.....)
}
\end{itemize}

\end{minipage}
\end{preview}

\begin{preview}
\begin{minipage}{\textwidth}

\setlength{\parskip}{0.4\baselineskip}
\begin{textblock*}{20cm}(2.1cm,2cm) % {block width} (coords) 
	{\color{red}{\large \textcircled{\small 4}}}
	\hspace{8cm}
	\color{blue}{\footnotesize \cc{逻辑与深度学习}{Logic and Deep Learning}}
\end{textblock*}
\vspace*{0.3cm} 

\cc{根据我的理论，理想的逻辑形式是这样的（各种元素的个数纯粹示意）：
}{
In my theory, the ideal logical structure is something like this (the numbers of elements may vary):
}
\begin{equation}
\label{fig:logic-symmetry-predicate-level}
\vcenter{\hbox{\includegraphics[scale=1]{logic-symmetry-predicate-level.png}}}
\end{equation}

\cc{相比之下，我们目前可以写出来的 代数关系 $p \wedge q = p \wedge q$ 只表达了这种结构：
}{
In contrast, the algebraic relation $p \wedge q = p \wedge q$ expresses only this structure:
}
\begin{equation}
\label{fig:logic-symmetry-propositional-only}
\vcenter{\hbox{\includegraphics[scale=1]{logic-symmetry-propositional-only.png}}}
\end{equation}
\cc{相比于 图 (\ref{fig:logic-symmetry-propositional-only})，图 (\ref{fig:logic-symmetry-predicate-level}) 添加了 $\atom$ 的约束，\uline{但这约束怎样用代数表示}？
}{
Compared to figure (\ref{fig:logic-symmetry-propositional-only}), figure (\ref{fig:logic-symmetry-predicate-level}) is additionally constrained by the $\atom$ structure.  \uline{But how can we express this constraint algebraically}?
}

\cc{而 \textbf{Transformer} 处理 命题 和 概念 的方式是这样：
}{
And this is how the \textbf{Transformer} handles propositions and atomic concepts:
}
\begin{equation}
\label{fig:logic-symmetry-Transformer}
\vcenter{\hbox{\includegraphics[scale=1]{logic-symmetry-Transformer.png}}}
\end{equation}
\cc{它没有 explicit 的命题结构，而是用特别的 token 表示句子的\textbf{终结}，当然还有 positional encoding 这些「伎俩」。 所以，Transformer 是一种比较 \textit{ad hoc} 的设计，我们应该可以改进它。
}{
It does not represent propositions (= sentences) explicitly, but it uses a special ``stop'' token to signify the \textbf{end} of sentences, and there are other ``tricks'' such as \textbf{positional encoding}.  It seems to be a rather \textit{ad hoc} design, we should be able to improve it.
}

\end{minipage}
\end{preview}

\begin{preview}
\begin{minipage}{\textwidth}

\setlength{\parskip}{0.4\baselineskip}
\begin{textblock*}{20cm}(2.1cm,2cm) % {block width} (coords) 
	{\color{red}{\large \textcircled{\small 5}}}
	\hspace{8cm}
	\color{blue}{\footnotesize \cc{逻辑与深度学习}{Logic and Deep Learning}}
\end{textblock*}
\vspace*{0.3cm} 

\cc{现在我们企图回答那\uline{最重要的问题}： 怎样用代数形式表达「命题是由概念原子组成的」？
}{
Now we try to answer \uline{the crucial question}:  how to express algebraically that ``propositions are composed of conceptual atoms''?
}

\cc{亦即是说，以下这两个结构的分别在哪里？ 如何用代数表达这不同？
}{
That is to say, what is the difference between the following two structures?  How to express this difference algebraically?
}
\begin{equation}
\vcenter{\hbox{\includegraphics[scale=0.6]{logic-symmetry-predicate-level-1.png}}}
\quad \mbox{vs} \quad
\vcenter{\hbox{\includegraphics[scale=0.6]{logic-symmetry-propositional-only-1.png}}}
\end{equation}
\cc{这就像问 $ 0...9 \times 0...9 $ 跟 $ 00...99 $ 的分别（基本上没有分别，它们是 isomorphic）。 
}{
This is like asking the difference between $0...9 \times 0...9$ and $00...99$ (they are isomorphic).
}

\cc{类似地，
}{
Similarly,
}
\begin{equation}
\{ \mbox{ John, Mary } \} \times \{ \mbox{ human, god, worm } \}
\end{equation}
\cc{跟}{and the $2 \times 3 = 6$ propositions}
\begin{equation}
\{ \mbox{ John is human }, \mbox{ Mary is human }, .... \}
\end{equation}
\cc{等 $2 \times 3 = 6$ 个命题 也是同构的。 但前者是由两组不同的概念结合而成，它的成分可以被 $\forall$ 或 $\exists$ 量化； 后者是 命题逻辑，那些命题是不可分割的，也不可以拆开来量化。 
}{
are also isomorphic.  But the former is a composition of two different concepts, where components can be individually quantified by $\forall$ or $\exists$;  The latter is propositional logic, where propositions are indivisible and cannot be internally quantified.
}

\cc{但由于 $\atom \in$ 非交换自由群（最少结构的群），它没有像 $a \cdot b = b \cdot a$ 那样的对称性公式。
}{
But since $\atom$ belongs to a non-commutative free group (ie, the group with the least structure), it does not possess a simple symmetry like $a \cdot b = b \cdot a$.
}

% 似乎要考虑  $\atom$ 的群结构是如何影响 逻辑 rule (\ref{fig:logic-symmetry-predicate-level}) 的输入和输出？ 类似这样：
%\begin{equation}
%q_1 \cdot q_2 \; \Longleftarrow \; p_{11} \cdot p_{12} \; \wedge \; p_{21} \cdot p_{22}
%\end{equation}
%它跟这样有什么不同：
%\begin{equation}
%Q \; \Longleftarrow \; P_1 \; \wedge \; P_2 \quad ?
%\end{equation}

% $Q$ 是由两件东西组成，但这两件东西可以换成另外两件。 但那就不再是同一个 rule.  如果要维持是同一个 rule，则 任何 $\atom$ 元素不可以交换或更换。 那是不是需要考虑所有的 rules？

% 或者可以考虑一个 $\forall$ rule，它包含很多个 instantiated rules.  而它的 substitutions 总是以 群元素为 unit.  这一点可以怎样表示？

% 但其实当 rule 改变时，它似乎也是根据群元素的边界而改变的。 似乎一定要涉及大量的 rules 才可以表达 $\atom$ 的对称性。

% 但从机器学习的角度来看，rules 的更新 似乎没有必要 遵从 $\atom$ 的边界？

% 从经典 AI 的角度看，lattice of rules 结构 就是 algebra of atomic concepts 的结构。

% The proposition structure $P$ is made up of atoms $a$ from a free monoid $A$, and the rule can be quantified by $\forall$ and $\exists$ over such atoms.  ``The rule can be quantified'' means the mapping does not just send one compound element to another element, but that parts of the compound element can be varied and the output element would vary according to the rules of $\forall$ or $\exists$ as adjunctions to substitution maps.

% The \textbf{Atomic Condition} says that the input and output of a rule are made up of atoms that can vary according to $\forall$ and $\exists$ as adjoint functors.

% The \textbf{Atomic Condition} says that each $P_i = a_{i1} ... a_{ik}$ where some $a_{ij}$ \uline{can vary} according to $\forall$ and $\exists$ as adjoint functors.

% The \textbf{Atomic Condition} says that each $P_i = a_{i1} ... a_{ik}$ where some $a_{ij}$ \uline{can be copied} (possibly with some transformation) to another location.  And the transformation has to accord with $\forall$ and $\exists$ as adjunctions.

% The \textbf{Atomic Condition} says that each $P_i = a_{i1} ... a_{ik}$ where some $a_{ij}$ \uline{can be copied} (possibly with some transformation) to another location.  And the transformation has to accord with $\forall$ and $\exists$ as adjunctions.

% The \textbf{Atomic Condition} says that each $P_i = a_{i1} ... a_{iK}$ where some $a_{ih} = T_{\forall}(a_{jk})$ and the transformation $T_{\forall}$ has to accord with $\forall$ as an adjunction to a substitution functor.

\cc{经过一番分析之后 我得到了「命题是由概念原子构成的」以下条件：
}{
After some analysis I arrived at the following condition for ``propositions are made of conceptual atoms'':
}

\begin{tcolorbox}[colback=white, enhanced]
\newtheorem*{condition}{Atomic Condition}
\begin{condition}[AC]
	Each proposition $P_i$ is made up of $K$ atoms:
	\begin{equation}
	P_i = a_{i1} \cdot ... \cdot a_{iK}
	\label{eqn:atomic-condition-1}
	\end{equation}
	where optionally some atoms can be \textbf{copied} to other locations (with a non-linear transformation $\tau$, if they are copied to the output layer) via:
	\begin{equation}
	a_{ih} = a_{jk} \quad \mbox{or} \quad a_{ih} = \tau(a_{jk})
	\label{eqn:atomic-condition-2}
	\end{equation}
	and the transformation $\tau$ has to accord with $\forall$ or $\exists$ as adjunctions to a substitution functor.
\end{condition}
\end{tcolorbox}

\cc{其实 $\tau$ 只需要是连续函数，就可以符合上述条件。 所以 Atomic Condition 的重点在于 (\ref{eqn:atomic-condition-1}) 和 (\ref{eqn:atomic-condition-2}) 这两个\textbf{等式}，其实是非常简单的。 $\forall$ 和 $\exists$ 作为伴随函子 的范畴论描述 比较复杂，我们在 \hyperlink{page:appendix-A}{附录 A} 里解释。
}{
The essence of the Atomic Condition lies in the two \textbf{equations} (\ref{eqn:atomic-condition-1}) and (\ref{eqn:atomic-condition-2}), which are actually very simple.  The category-theoretic description of $\forall$ and $\exists$ as adjoint functors is quite advanced, but not essential, and we shall explain them in  \hyperlink{page:appendix-A}{appendix A}.  In fact, $\tau$ only needs to be a continuous function to meet the above requirement.
}

\cc{那么 等式 (\ref{eqn:atomic-condition-2}) 里面的 ``='' 是来自哪里？ 其实太明显了，它就是逻辑 rule 里面 将变量「syntactically 搬动」的动作：
}{
So where does the ``='' in equation (\ref{eqn:atomic-condition-2}) come from?  In fact, it is too obvious, it is just the action of syntactically ``moving'' variables in a logic rule, eg:
}
\vspace{0.5cm}
\begin{equation}
\forall X, Y, Z.  \;\;  \text{grandfather}({\color{red}X} \tikzmark{x}, {\color{red}Z} \tikzmark{z}) \leftarrow \text{father}({\color{red}X} \tikzmark{p}, {\color{red}Y} \tikzmark{y}) \wedge \mbox{father}({\color{red}Y} \tikzmark{q}, {\color{red}Z} \tikzmark{r})
\begin{tikzpicture}[overlay,remember picture,out=45,in=135,distance=1.1cm]
\draw[-,red, transform canvas={shift={(-5pt,18pt)}}] (x.center) to (p.center);
\draw[-,red, transform canvas={shift={(-5pt,18pt)}}] (y.center) to (q.center);
\draw[-,red, transform canvas={shift={(-5pt,-3pt)}}, out=-45,in=225] (z.center) to (r.center);
\end{tikzpicture}
\label{eqn:linkage-father}
\end{equation}
\cc{正是 这些「搬动」，构成了「命题是由概念组成的」结构。
}{
It is due to such ``movements'' that gives rise to the structure ``propositions as composed of atomic concepts''.
}

\end{minipage}
\end{preview}

\begin{preview}
\begin{minipage}{\textwidth}

\setlength{\parskip}{0.4\baselineskip}
\begin{textblock*}{20cm}(2.1cm,2cm) % {block width} (coords) 
	{\color{red}{\large \textcircled{\small 6}}}
	\hspace{8cm}
	\color{blue}{\footnotesize \cc{逻辑与深度学习}{Logic and Deep Learning}}
\end{textblock*}
\vspace*{0.3cm} 

\cc{\textbf{Self-Attention} 的本质 可以这样理解（抽象注意力结构）：
}{
The essence of \textbf{Self-Attention} can be understood as follows (what I call abstract Self-Attention):
}
\begin{equation}
\label{fig:abstract-self-attention}
\vcenter{\hbox{\includegraphics[scale=1]{essence-of-self-attention.png}}}
\end{equation}
\cc{这垂直的「軸」结构 ({\color{red}红色})，重复在每一条轴上。  所以，当 输入的元素 \textbf{交换}时，输出也随着交换。 这就是 Self-Attention 能达到 \textbf{equi-variant} 效果的原因。
}{
This vertical ``axis'' ({\color{red}red}) is repeated per each input token.  So, when the input elements are \textbf{swapped}, the output is also swapped.  This is how Self-Attention achieves \textbf{equi-variance}.
}

\cc{而我们想用 类似以上 Self-Attention 的方法，解决 逻辑结构 的问题：
}{
We want to apply a similar method to logical structure:
}
\begin{equation}
\vcenter{\hbox{\includegraphics[scale=1]{logic-symmetry-logic-Transformer.png}}}
\end{equation}

\cc{这里有一个很重要的重点\footnote{谢谢 “子鱼” 告诉我这个重要信息。}： Self-Attention 的前身是来自 Graves \textit{et al.} 的 《Neural Turing Machine》 的 \textbf{content-addressable memory}.  我们很有理由将它看成是一种 \textbf{记忆体}。
}{
Here is a very important point\footnote{Thanks to ``Ziyu'' for telling me this. }: The precursor of Self-Attention is the \textbf{content-addressable memory} from Graves \textit{et al}'s ``Neural Turing Machines'' \footnote{The book ``Fundamentals of Deep Learning'' [Buduma \& Locascio 2017] has a very nice explanation of Neural Turing Machines. }.  We have good reason to regard Self-Attention as a form of \textbf{memory}.
}

\cc{我们要比较 两种做法，前者是简单直接的经典 rule base 结构，后者是以 Self-Attention 代替 rule base：
}{
Let's compare the two approaches.  One is the na\"{i}ve classical rule-base structure, and the other uses Self-Attention instead of a rule base:
}
\begin{equation}
\label{fig:rule-base}
\vcenter{\hbox{\includegraphics[scale=1]{shallow-rule-base.png}}}
\end{equation}
\hrule
\begin{equation}
\vcenter{\hbox{\includegraphics[scale=0.9]{rete-explained-3b.png}}}
\tag{\ref{fig:self-attention-as-Rete}}
\end{equation}
\cc{大家要感受到 Transformer 是一种非常 ``twisted'' 的处理 rules matching 的方式。 这个对应很不明显，以至于我们很难分辨出 Transformer 那边的 rules 长什么样子。 然而我觉得 Transformer 的设计者们 或许多少有意识到它跟 rule-based systems 的相似性。 特别地，看看以下这条逻辑 rule：
}{
You should get the sense that the Transformer is a very ``twisted'' way of representing logic rules.  The correspondence is so indirect that it is difficult for us to see what the rules look like inside the Transformer.  However, I think the designers of Transformer might have had at least an inkling of its similarities to rule-based systems.  In particular, look at the following logic rule:
}
\vspace{0.5cm}
\begin{equation}
\forall X, Y, Z.  \;\;  \text{grandfather}(X \tikzmark{x1}, Z \tikzmark{z1}) \leftarrow \text{father}(X \tikzmark{x2}, {\color{red}Y} \tikzmark{y1}) \wedge \mbox{father}({\color{red}Y} \tikzmark{y2}, Z \tikzmark{z2})
\begin{tikzpicture}[overlay,remember picture,out=45,in=135,distance=1.1cm]
\draw[-, transform canvas={shift={(-5pt,18pt)}}] (x1.center) to (x2.center);
\draw[-,red, transform canvas={shift={(-5pt,18pt)}}] (y1.center) to (y2.center);
\draw[-, transform canvas={shift={(-5pt,-3pt)}}, out=-45,in=225] (z1.center) to (z2.center);
\end{tikzpicture}
\tag{\ref{eqn:linkage-father}}
\end{equation}
\cc{这 rule 的前提有两个条件，出现两次的变量 $Y$ 必须相等（{\color{red}红色}），matching 才算成功。 而这种在 rule 的前提内部进行的 \textbf{比较} (comparison) 运作，正是 Self-Attention 可以方便地做到的。
}{
The premise of this rule has two clauses, the variable $Y$ that appears twice must be identical ({\color{red}red}), for this matching to be considered successful.  And this kind of \textbf{comparison} operation within the premises of the rule is exactly what Self-Attention can perform conveniently. 
}

\end{minipage}
\end{preview}

\begin{preview}
\begin{minipage}{\textwidth}

\setlength{\parskip}{0.4\baselineskip}
\begin{textblock*}{20cm}(2.1cm,2cm) % {block width} (coords) 
	{\color{red}{\large \textcircled{\small 7}}}
	\hspace{8cm}
	\color{blue}{\footnotesize \cc{逻辑与深度学习}{Logic and Deep Learning}}
\end{textblock*}
\vspace*{0.3cm} 

\cc{我觉得目前要回答的几个关键问题是：
}{
Some key questions to be answered:
}
\begin{itemize}
\cc{\item 根据例如 刘乾 \textit{et al} 的论文\footnote{Qian Liu, Shengnan An, Jian-Guang Lou, Bei Chen, Zeqi Lin, Yan Gao, Bin Zhou, Nanning Zheng, and Dongmei Zhang. \textit{Compositional Generalization by Learning Analytical Expressions.} Advances in Neural Information Processing Systems 33 (2020).}，Transformer 做不到某些 逻辑语法上的运作，问题出在哪里？ 似乎不是 Transformer 根本无法学习那种语法，而是 它不能纯粹靠 prompt 做到。 但其实 prompt 是否具有深层意义，还是它只是一个 hack？  我们没有 explicitly「告诉」Transformer 它应该怎么做，那它做不到是不是一个真的缺憾？ 我觉得很难判断，令 prompt 的研究方向笼罩在迷雾之中。
}{
\item According to eg. Qian Liu's paper \footnote{Qian Liu, Shengnan An, Jian-Guang Lou, Bei Chen, Zeqi Lin, Yan Gao, Bin Zhou, Nanning Zheng, and Dongmei Zhang. \textit{ Compositional Generalization by Learning Analytical Expressions.} Advances in Neural Information Processing Systems 33 (2020).}, Transformers often fail at certain logic and syntactic questions.  Where is the problem?  It is not the case that Transformers cannot learn the syntax at all, but it cannot do so with prompts only.  Prompts are just a hack to encode contextual meaning in tokens.  It seems that this contextual meaning is sometimes insufficient to answer certain questions.  If we have not explicitly ``told'' the Transformer what it should do, is it a real shortcoming that it failed to solve those problems?  This is a problem with Language Models which I think logic-based AGI will provide a clearer solution.
}

\cc{\item 现在考虑图 (\ref{fig:rule-base}) 即 rule base 的 na\"{i}ve 学习算法。 这个算法当然是很慢的，因为要比较两个集合（working memory 和 rule heads) 的相似性。 假设集合的大小固定为 $M$ 和 $N$，那需要 $M \times N$ 次的 dot products，而这只是比较了一条 rule.  所有 rules 还要用 softmax 相加。 当 rule base 很大的时候，这个算法似乎不太实际。
}{
\item Now consider the na\"{i}ve rule-base algorithm in diagram (\ref{fig:rule-base}). This algorithm is of course very slow, as we need to compute the similarity between two sets (working memory and rule heads).  Assuming that the size of the sets are fixed at $M$ and $N$, then $M \times N$ dot products need to be computed, and this is for just 1 rule.  The result from all rules need to be added with softmax.  When the rule base is very large, this seems impractical.
}
	
\cc{\item 图 (\ref{fig:rule-base}) 还有可能出现 旧有的逻辑 rule learning 算法的问题，亦即 ``\textbf{plateau problem}''.  举例来说，用 Prolog 语言写 append 函数：\\
}{
\item Diagram (\ref{fig:rule-base}) may suffer from an old problem of logic rule-learning, known as the ``\textbf{plateau problem}''. For example, the ``append'' function in Prolog:\\
}
	\code{append(X,Y,Z) :-} \\
	\tab \code{list(X), head(X,X1), tail(X,X2), append(X2,Y,W), cons(X1,W,Z).} \\
\cc{这个 rule 有 5个前提。 当 rule 被学习时，前提被逐个加进去，但 rule 的「得分值」一直是零，直到最后的前提 加进去了，得分才突然升到 100\%.  对于机器学习来说，这情况是很糟的。 而 Transformer 将 rules「扭曲地」缠在一起，这做法会不会反而有利于避免困在 local minima 呢？
}{
This rule has 5 premises.  As the rule is learned, premises are added one by one, but the ``score value'' of the rule remains zero until the very last premise is added, and the score suddenly jumps to 100\%.  For machine learning, this situation is terrible.  As the Transformer ``mingles'' logic rules together, it may avoid being trapped in local minima.
}
	
\cc{\item 可能存在 介乎 Transformer 与 na\"{i}ve rule base 之间的算法，它比 Transformer 有更强的逻辑结构，但比 na\"{i}ve rule base 用了更多类似 Self-Attention 的矩阵运算来加速？
}{
	\item Can we design an algorithm halfway between Transformer and na\"{i}ve rule base, which has stronger logical structure than Transformer, but uses efficient matrix operations similar to Self-Attention?
}
\end{itemize}

\end{minipage}
\end{preview}

\begin{preview}
\begin{minipage}{\textwidth}

\setlength{\parskip}{0.4\baselineskip}
\begin{textblock*}{20cm}(2.1cm,2cm) % {block width} (coords) 
	{\color{red}{\large \textcircled{\small 8}}}
	\hspace{8cm}
	\color{blue}{\footnotesize \cc{逻辑与深度学习}{Logic and Deep Learning}}
\end{textblock*}
\vspace*{0.3cm} 

\cc{现时想到的一个比较可行的 architecture：
}{
Currently I can think of a more practical architecture as follows:
}
\begin{equation}
\cc{  \vcenter{\hbox{\includegraphics[scale=1]{seq-to-seq-seq-with-Transformer.png}}}      }{
      \vcenter{\hbox{\includegraphics[scale=1]{seq-to-seq-seq-with-Transformer-en.png}}}   }
\end{equation}
\begin{itemize}
\cc{\item 在{\color{blue}蓝色}结构里，每个命题要由 fixed \# of 概念原子组成。
}{
\item In the {\color{blue}blue} structure, each proposition shall consist of a fixed \# of concept atoms.
}

\cc{\item 但抽象的 Self-Attention 结构也可以容许 \textbf{可变长度} 的命题，只要能计算到 命题之间的 \textbf{dot product} (similarity) ，还有 读取 固定长度的 \textbf{矩阵} 记忆体。
}{
\item Abstract Self-Attention allows \textbf{variable length} propositions, as long as we can calculate the \textbf{dot product} (similarity) between propositions, and if we know how to retrieve from the (fixed-length?) memory \textbf{matrix}.
}

\cc{\item {\color{red}红色}结构： 如何从 不定长度的句子 产生数量和长度不同的命题？ 这就是以前谈过的 sequence to sequence-of-sequences 问题。 这也可以用 ``lossy'' Self-Attention 解决。
}{
\item {\color{red}Red} structure:  We need to read a natural-language sentence and break it down into a (variable) number of propositions (of variable lengths).  This is the ``sequence to sequence-of-sequences'' problem that I have been talking about for some years.  This may be solved with ``lossy'' Self-Attention.
}
	
\end{itemize}

\end{minipage}
\end{preview}

\begin{preview}
\begin{minipage}{\textwidth}
\hypertarget{page:appendix-A}{}

\setlength{\parskip}{0.4\baselineskip}
\begin{textblock*}{20cm}(2.1cm,2cm) % {block width} (coords) 
	{\color{red}{\large \textcircled{\small A}}}
	\hspace{8cm}
	\color{blue}{\footnotesize \cc{逻辑与深度学习}{Logic and Deep Learning}}
\end{textblock*}
\vspace*{0.3cm} 

\cc{在这个附录里，我们用简单的方式解释一下 $\forall$ 和 $\exists$ 的理论。 
}{
	In this appendix, we explain the categorical theory of $\forall$ and $\exists$ in a simple way.
}

\cc{以下是一个关系 $R$，例如「$Y$爱$X$」，$X, Y$ 都是「人」的集合；两个相同的拷贝。 例如 对角线 代表爱自己（有些人不爱自己）。 注意这个图也不是 对角线 对称的，否则就没有「失恋」了。 将关系 $R$ 的图像 \textbf{投影} 到 $X$ 轴上，可以得到 $\forall_Y$ 和 $\exists_Y$ 集合。 $\forall_Y$ 集合 代表那些「人人都爱」的 $X$，$\exists_Y$ 集合代表那些「有人爱他」的 $X$:
}{
	The following is a relation $R$, such as "$Y$ loves $X$", where $X, Y$ are both sets of ``people''; two identical copies. For example, the diagonal represents loving oneself (some people don't love themselves). Note that this graph is not symmetric about the diagonal, otherwise there would be no such thing as ``heart break''.  Projecting the relation $R$ onto the $X$ axis yields the $\forall_Y$ and $\exists_Y$ sets. The $\forall_Y$ set represents those in $X$ whom ``everybody loves'', and $\exists_Y$ represents those in $X$ whom ``somebody loves'':
}
\begin{equation}
\vcenter{\hbox{\includegraphics[scale=0.8]{forall-and-exists.png}}}
\end{equation}
\cc{范畴论大师 Lawvere 发现，$\forall$ 和 $\exists$ 是一个所谓 \textbf{weakening functor} 的「伴随函子」，所谓 weakening 就是从一个只有 $X$ 变量的\textbf{论域} 扩充到有 $X,Y$ 两个变量的论域，而这里 $Y$ 纯粹是一个 \textbf{dummy} variable:
}{
	The category theorist Lawvere discovered that $\forall$ and $\exists$ are \textbf{adjunctions} to the so-called \textbf{weakening functor}, which means expanding from the variable domain $(X)$ to the variable domain $(X,Y)$, where $Y$ is just a \textbf{dummy} variable:
}
\begin{equation}
\begin{tikzcd}[column sep = 4cm, row sep = 0.3cm]
{}  & {} \arrow[l, swap, "\forall_Y"] \\
(X) \arrow[r, "\mbox{weakening}"] & (X,Y) \\
{}  & {} \arrow[l, swap, "\exists_Y"]
\end{tikzcd}
\end{equation}
\cc{例如 $\mbox{Love}(Y,X)$ 是带有两个变量的逻辑式子，但 $\forall Y. \mbox{ Love}(Y,X)$ 其实没有了 $Y$ 这个变量，因为它被 $\forall$ \textbf{绑定}了。
}{
	For example, $\mbox{Love}(Y,X)$ is a logic term with two variables, whereas $\forall Y. \mbox{ Love}(Y,X)$ actually does not contain the variable $Y$, as it is \textbf{bound} by the quantifier $\forall$.
}

\cc{所谓 \textbf{伴随} (adjoint) 的意思是： 有两个范畴：左边和右边。 你可以将 左边的东西搬到右边，在右边的范畴里做「\textbf{比较}」，而这个比较 同样地可以 把东西搬到左边做，两个比较是\textbf{等价}的。 这里「比较」的意思就是范畴内的 morphism, 例如在 $\mathsf{Set}$ 范畴里，比较就是 set inclusion.  
}{
	What \textbf{adjunction} means:  Given two categories: left and right.  You can move objects from the left to the right, and ``\textbf{compare}'' them in the right category.  This comparison can also be performed in the left category by moving objects to the left.   And these two ways of comparison are \textbf{equivalent}.  By ``comparison'' we mean morphism in the category.  For example, in the category $\mathsf{Set}$, comparison is set inclusion.
}

\cc{伴随函子 并不是唯一的，所以 weakening 分别有 $\forall$ 和 $\exists$ 两个伴随。
}{
	Adjunctions are not unique, so weakening has two adjoints, $\forall$ and $\exists$.
}

\cc{Lawvere 将 量词 $\forall$ 和 $\exists$ 推广得更一般： 「简单」的 weakening functor 是基于 笛卡尔积 $X \times Y$； Lawvere 将它扩充到任何 \textbf{substitution} functor.  但我暂时缺乏这方面的例子，不清楚它对我们的应用有什么益处。
}{
	Lawvere's work made the $\forall$ and $\exists$ quantifiers more general.  The ``simple'' weakening functor is based on the Cartesian product $X \times Y$, but Lawvere generalized it to arbitrary \textbf{substitution} functors.  (At this time I can't give any examples of this, so I don't know how exactly this generalization can be advantageous for our applications....)
}

\end{minipage}
\end{preview}

\begin{preview}
\begin{minipage}{\textwidth}

\setlength{\parskip}{0.4\baselineskip}
\begin{textblock*}{20cm}(2.1cm,2cm) % {block width} (coords) 
	{\color{red}{\large \textcircled{\small B}}}
	\hspace{8cm}
	\color{blue}{\footnotesize \cc{逻辑与深度学习}{Logic and Deep Learning}}
\end{textblock*}
\vspace*{0.3cm} 

%我们希望 以代数形式表达 谓词 $\atom$ 的颗粒性。 
\cc{在 范畴逻辑 里面有 \textbf{Beck-Chevalley} 条件和 \textbf{Frobenius} 条件，或许是我们所需的对称性？ 但细看之后，发觉还是不能解决问题.....  For completeness，我还是描述一下，没兴趣的可以略过。
}{
In the study of categorical logic, there are the \textbf{Beck-Chevalley} condition and \textbf{Frobenius} condition.  Could they be the conditions I was looking for?  Upon closer look, I found that they are not the solution.  For completeness, I will describe them, but the reader can skip if they're not interested.
}

\cc{首先考虑比较容易明白的 \textbf{Frobenius} 条件。 在逻辑上，它等于说：
}{
The \textbf{Frobenius} condition seems easier to understand.  Logically, it is equivalent to:
}
\begin{equation}
\exists x. [ \phi \wedge \psi(x) ] \equiv \phi \wedge \exists x. \psi(x).
\end{equation}
\cc{由于 经典逻辑 AI 普遍使用 $\forall$ 而忽略 $\exists$，我将上式改写成：
}{
Since logic-based AI generally uses $\forall$ and ignores $\exists$, I rewrite the above formula as:
}
\begin{equation}
\label{eqn:Frobenius-condition}
\forall x. [ \phi \vee \psi(x) ] \equiv \phi \vee \forall x. \psi(x).
\end{equation}
\cc{但问题是，(\ref{eqn:Frobenius-condition}) 式的左边和右边，其对应的神经网络 (\ref{fig:logic-symmetry-predicate-level}) 是一样的（看不出有分别）。 也就是说这个差别可能太 subtle 了，它并不影响我们实际 implement 的神经网络。
}{
The problem is that the left and right sides of equation (\ref{eqn:Frobenius-condition}) correspond to identical neural networks (\ref{fig:logic-symmetry-predicate-level}).  In other words, the condition is too subtle, and it does not affect the neural network we actually implement.
}

%\cc{在逻辑里，任何变量 例如 $x,y$ 等，必须被 $\forall$ 或 $\exists$ quantify，否则不成为合法的句子。 所以 表达 谓词结构的对称性，也很可能要涉及 $\forall$ 或 $\exists$.
%}{
%In logic, any variable such as $x, y$, etc. must be quantified by $\forall$ or $\exists$, otherwise it will not become a legal sentence. So to express the symmetry of the predicate structure, it is also likely to involve $\forall$ or $\exists$.
%}

\end{minipage}
\end{preview}

\begin{preview}
\begin{minipage}{\textwidth}
		
\setlength{\parskip}{0.4\baselineskip}
\begin{textblock*}{20cm}(2.1cm,2cm) % {block width} (coords) 
	{\color{red}{\large \textcircled{\small C}}}
	\hspace{8cm}
	\color{blue}{\footnotesize \cc{逻辑与深度学习}{Logic and Deep Learning}}
\end{textblock*}
\vspace*{0.3cm} 

\cc{以前说过，谓词逻辑 带来 \textbf{fibration} 或 \textbf{indexing} 结构。 Beck-Chevalley 和 Frobenius 条件 基本上是说，这 纤维结构 是 ``preserved by re-indexing functors''.
}{
As my categorical logic tutorial said before, predicate logic leads to \textbf{fibration} or \textbf{indexing} constructs. The Beck-Chevalley and Frobenius conditions basically say that the fiber structure is ``preserved by re-indexing functors''.
}

\cc{这是 fibration 结构的示意图：
}{
Here is a diagram of a fibration:
}
\begin{equation}
\vcenter{\hbox{\includegraphics[scale=0.7]{etale-space.png}}}
\end{equation}
\cc{这整个结构 叫 \textbf{bundle}，而 \textbf{sheaf} 是 bundle 加上某个特殊的 拓扑结构。 
}{
This whole structure is called a \textbf{bundle}, and \textbf{sheaf} is a bundle plus some topological constraint.
}

\cc{在 $(A,f)$ 和 $(B,g)$ 两个 bundle 之上可以定义 \textbf{fibred product} of $A$ and $B$ over $I$, 记作 $A \times_I B$:
}{
The \textbf{fibred product} of $A$ and $B$ over $I$ can be defined on two bundles $(A,f)$ and $(B,g)$, denoted as $A \times_I B$ :
}
\begin{equation}
\label{eqn:fibred-product}
\begin{tikzcd}[sep = 3cm]
A \times B \arrow[r, "q"] \arrow[d, swap, "p"] \arrow[rd, "h"] & B \arrow[d, "g"] \\
A \arrow[r, swap, "f"] & I
\end{tikzcd}
\end{equation}
\cc{其中 $h = f \circ p = g \circ q$.  这也是一个 \textbf{pullback}.
}{
where $h = f \circ p = g \circ q$. This is also a \textbf{pullback}.
}

\cc{\textbf{Beck-Chevalley} 条件是说 下面这幅图 commute： 
}{
The \textbf{Beck-Chevalley} condition says that the following diagram commutes:
}
\begin{equation}
\label{eqn:Beck-Chevalley}
\begin{tikzcd}[column sep = 3cm]
K \times J \arrow[r, "u \;\times\; id"] \arrow[d, swap, "\pi"] & I \times J \arrow[d, "\pi"] \\
K \arrow[r, swap, "u"] & I
\end{tikzcd}
\end{equation}
\cc{其中 $\pi$ 就是代表 量词 $\forall$ 或 $\exists$ 的 投影，它们是 weakening map $\pi^*$ 的伴随映射。 
}{
where $\pi$ is the projection representing the quantifiers $\forall$ or $\exists$, which are adjoints to the weakening map $\pi^*$.
}

\cc{Beck-Chevalley 条件并不完全是空洞的；它有可能不成立。 有一个反例是 Pitts 提出的： 考虑 $X \times Y$， 其中 $X = Y = \mathbb{N} \cup \{\infty\}$ 亦即 自然数加上 $\infty$ 作为 top element； 但 $Y$ 是用 discrete order，亦即所有 order 都是 = 关系。  $A$ 是 $X \times Y$ 上的关系： $A = \{ (x,y) \in \mathbb{N \times N} \;|\; x \le y \}$.  那么 $\exists y. (x,y) \in A$ 会是整个 $X$ 集合。 如果考虑 DCPO 范畴，我们要求 fibration of Scott-closed subsets (ordered by inclusion) over DCPO.  $\exists y. A$ 的 Scott closure 的条件是 它是一个 lower set closed under directed joins; 而这个 Scott closure 条件似乎不成立，因而导致 图 (\ref{eqn:Beck-Chevalley}) 不 commute.（我对 Scott closure 的细节不太理解）
}{
The Beck-Chevalley condition is not entirely vacuous; it may not hold.  There is a counter-example from Pitts: Consider $X \times Y$, where $X = Y = \mathbb{N} \cup \{\infty\}$ are the natural numbers plus $\infty$ as top element.  $Y$ has discrete order, ie, all orders are the ``='' order. $A$ is the relationship on $X \times Y$: $A = \{ (x,y) \in \mathbb{N \times N} \;|\; x \le y \}$. Then $\exists y. (x,y) \in A$ will be the entire set of $X$. If we consider the DCPO category, we require the fibration of Scott-closed subsets (ordered by inclusion) over DCPO. The condition for Scott closure of $\exists y. A$ is that it is a lower set closed under directed joins; and this Scott closure condition seems to be violated, thus causing the graph (\ref{eqn:Beck-Chevalley}) not to commute. (I do not understand the details of Scott closure)
}

\end{minipage}
\end{preview}

\begin{preview}
\begin{minipage}{\textwidth}
		
\color{teal}

\cc{首先以函数的方式表达 Self-Attention 结构：
}{
	First express the Self-Attention structure in a functional way:
}
\begin{eqnarray}
\cc{
	\boxed{\mbox{输出命题 $O_i$ 由原子 $b_i$ 组成}} \quad O_i &=& [b_1 ... b_K] \\
	\boxed{\mbox{输入命题 $P_i$ 由原子 $a_i$ 组成}} \quad P_i &=& [a_1 ... a_K] \\
}{
	\boxed{\mbox{output proposition $O_i$ is composed of atoms $b_i$ }} \quad O_i &=& [b_1 ... b_K] \\
	\boxed{\mbox{input proposition $P_i$ is composed of atoms $a_i$ }} \quad P_i &=& [a_1 ... a_K] \\
}
\boxed{\mbox{Self-Attention}} \quad O_i = \alpha(P_i \;; P_1 ... \hat{P_i} ... P_N)
\end{eqnarray}
\cc{$P_1 ... \hat{P_i} ... P_N$ 的意思是 $P_1 ... P_N$ 除了 $P_i$. \\
}{
	$P_1 ... \hat{P_i} ... P_N$ means $P_1 ... P_N$ except $P_i$. \\
}
\cc{$\alpha(P_i \;; ... )$ 是图 (\ref{fig:abstract-self-attention}) 的函数结构，也可以理解为 以 $P_i$ 为 query 的 self Attention.
}{
	$\alpha(P_i \;; ... )$ is the function structure of the graph (\ref{fig:abstract-self-attention}), and it can also be understood as the self Attention with $P_i$ as the query.
}

How to measure similarity between $(P_i, Q_i)$?
\begin{equation}
\argmin_i \sum_i \min_j \langle P_i, Q_j \rangle
\end{equation}

\begin{itemize}
\cc{\item 首先留意到，轴心结构 只对 命题层次有用，它的作用不会延伸到 概念原子层次。 然而，有监于 Transformer 也没有充分利用 交换不变性，然而它却因为用了矩阵乘法而变得很有效率，所以从效率的角度看，也有将 轴心结构 延伸到 原子层面的理由。
}{
	\item First notice that the pivot structure is only useful at the propositional level, and its effect does not extend to the conceptual atomic level. However, since Transformer does not take full advantage of the exchange invariance, it becomes very efficient because it uses matrix multiplication, so from an efficiency point of view, there are also reasons to extend the axis structure to the atomic level.
}

\cc{\item 另一个可以尝试的想法是： 直接 hard-code copying mechanism.  这可以怎样用 Attention 做到？  以前分析过了，copy 并不容易，因为需要 winner takes all.
}{
	\item Another idea to try is: direct hard-code copying mechanism. How can this be done with Attention? It has been analyzed before, copy is not easy, because winner takes all.
}

\cc{\item 但纯粹用 Hopfield network 又缺乏了 深度。 但似乎 在 RL 场景下，\textbf{广度} 也是重要的。
}{
	\item but purely using Hopfield network lacks depth. But it seems that in the RL scenario, \textbf{breadth} is also important.
}

\cc{\item 其实 只要有 输入/输出 的函数关系，就等价于有 逻辑 rules 的 KB 库。 问题是它用什么方法给出结论。
}{
	In fact, as long as there is an input/output functional relationship, \item is equivalent to a KB library with logic rules. The question is what method it uses to reach its conclusions.
}
\end{itemize}

\cc{Self-Attention 已经符合我们的要求，但我们想改进它。 主要有两个 idea： 其一是更直接的 copy mechanism，其二是 更细致的 函数 dependence.
}{
	Self-Attention already meets our requirements, but we want to improve it. There are two main ideas: one is a more direct copy mechanism, and the other is a more detailed function dependency.
}
\begin{equation}
\vcenter{\hbox{\includegraphics[scale=1]{logic-Transformer-1.png}}}
\end{equation}

\textbf{Copy:}
\begin{itemize}
\cc{\item Copy 不需要什么特别机制，输出就是输入。 但问题是怎样 combine with ``create'' operation.
}{
	\item Copy requires no special mechanism, the output is the input. But the question is how to combine with ``create'' operation.
}
\cc{\item 当然 可以用大家都熟悉的 softmax： $ \alpha \mbox{ copy} + \beta \mbox{ create} $, where $\alpha, \beta$ are outputs of softmax.
}{
	\item can of course use the familiar softmax: $ \alpha \mbox{ copy} + \beta \mbox{ create} $, where $\alpha, \beta$ are outputs of softmax.
}
\cc{\item 另一个想法是 content-addressable.  用 table-lookup 的形式，找可执行的 rules。 但有 variable matching 的问题。 
}{
	\item Another idea is content-addressable. Use table-lookup to find executable rules. But there is a problem with variable matching.
}
\end{itemize}

\textbf{Create:}
\begin{itemize}
\cc{\item 需要的是怎样的函数？
}{
	\item What kind of function is needed?
}
\end{itemize}
	
\end{minipage}
\end{preview}

\end{document}
